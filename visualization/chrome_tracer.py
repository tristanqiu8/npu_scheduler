#!/usr/bin/env python3
"""
Chrome Tracing Exporter
Chromeè¿½è¸ªæ ¼å¼å¯¼å‡ºå™¨ï¼Œç”¨äºæ€§èƒ½åˆ†æ
"""

import json
import time
from typing import List, Dict, Any, Optional
from core.enums import ResourceType, TaskPriority


class ChromeTracer:
    """Chromeè¿½è¸ªæ ¼å¼å¯¼å‡ºå™¨"""
    
    def __init__(self, scheduler):
        self.scheduler = scheduler
        self.events = []
        self.process_id = 1
        self.thread_ids = {}
        
    def export(self, filename: str = "trace.json"):
        """å¯¼å‡ºChromeè¿½è¸ªæ–‡ä»¶"""
        self._generate_events()
        self._write_trace_file(filename)
    
    def _generate_events(self):
        """ç”Ÿæˆè¿½è¸ªäº‹ä»¶"""
        self.events = []
        self._assign_thread_ids()
        
        # æ·»åŠ è¿›ç¨‹å’Œçº¿ç¨‹å…ƒæ•°æ®
        self._add_metadata_events()
        
        # æ·»åŠ ä»»åŠ¡æ‰§è¡Œäº‹ä»¶
        self._add_task_events()
        
        # æ·»åŠ èµ„æºç»‘å®šäº‹ä»¶
        self._add_binding_events()
        
        # æ·»åŠ æ€§èƒ½æ ‡è®°
        self._add_performance_markers()
    
    def _assign_thread_ids(self):
        """ä¸ºæ¯ä¸ªèµ„æºåˆ†é…çº¿ç¨‹ID"""
        thread_id = 1
        self.thread_ids = {}
        
        # NPUèµ„æº
        for resource in self.scheduler.resources[ResourceType.NPU]:
            self.thread_ids[resource.unit_id] = thread_id
            thread_id += 1
        
        # DSPèµ„æº
        for resource in self.scheduler.resources[ResourceType.DSP]:
            self.thread_ids[resource.unit_id] = thread_id
            thread_id += 1
    
    def _add_metadata_events(self):
        """æ·»åŠ å…ƒæ•°æ®äº‹ä»¶"""
        # è¿›ç¨‹åç§°
        self.events.append({
            "name": "process_name",
            "ph": "M",
            "pid": self.process_id,
            "args": {"name": "NPU Scheduler"}
        })
        
        # çº¿ç¨‹åç§°
        for resource_id, thread_id in self.thread_ids.items():
            self.events.append({
                "name": "thread_name",
                "ph": "M",
                "pid": self.process_id,
                "tid": thread_id,
                "args": {"name": resource_id}
            })
    
    def _add_task_events(self):
        """æ·»åŠ ä»»åŠ¡æ‰§è¡Œäº‹ä»¶"""
        for schedule in self.scheduler.schedule_history:
            task = self.scheduler.tasks[schedule.task_id]
            
            # å¤„ç†åˆ†æ®µä»»åŠ¡
            if task.is_segmented and hasattr(schedule, 'sub_segment_schedule') and schedule.sub_segment_schedule:
                self._add_segmented_task_events(task, schedule)
            else:
                self._add_regular_task_events(task, schedule)
    
    def _add_segmented_task_events(self, task, schedule):
        """æ·»åŠ åˆ†æ®µä»»åŠ¡äº‹ä»¶"""
        for i, (sub_seg_id, start_time, end_time) in enumerate(schedule.sub_segment_schedule):
            # æŸ¥æ‰¾å¯¹åº”èµ„æº
            sub_seg = None
            for ss in task.get_sub_segments_for_scheduling():
                if ss.sub_id == sub_seg_id:
                    sub_seg = ss
                    break
            
            if sub_seg and sub_seg.resource_type in schedule.assigned_resources:
                resource_id = schedule.assigned_resources[sub_seg.resource_type]
                thread_id = self.thread_ids.get(resource_id)
                
                if thread_id:
                    # è½¬æ¢ä¸ºå¾®ç§’ï¼ˆChrome Tracingä½¿ç”¨å¾®ç§’ï¼‰
                    ts = int(start_time * 1000)
                    dur = int((end_time - start_time) * 1000)
                    
                    self.events.append({
                        "name": f"{task.task_id}_seg{i}",
                        "cat": "task_segment",
                        "ph": "X",  # Complete event
                        "ts": ts,
                        "dur": dur,
                        "pid": self.process_id,
                        "tid": thread_id,
                        "args": {
                            "task_id": task.task_id,
                            "task_name": task.name,
                            "priority": task.priority.name,
                            "runtime_type": task.runtime_type.value,
                            "segment_id": sub_seg_id,
                            "resource_type": sub_seg.resource_type.value,
                            "segment_index": i
                        }
                    })
    
    def _add_regular_task_events(self, task, schedule):
        """æ·»åŠ å¸¸è§„ä»»åŠ¡äº‹ä»¶"""
        for seg in task.segments:
            if seg.resource_type in schedule.assigned_resources:
                resource_id = schedule.assigned_resources[seg.resource_type]
                thread_id = self.thread_ids.get(resource_id)
                
                if thread_id:
                    # è®¡ç®—æ—¶é—´
                    resource_unit = next((r for r in self.scheduler.resources[seg.resource_type] 
                                        if r.unit_id == resource_id), None)
                    if resource_unit:
                        duration = seg.get_duration(resource_unit.bandwidth)
                        start_time = schedule.start_time + seg.start_time
                        
                        # è½¬æ¢ä¸ºå¾®ç§’
                        ts = int(start_time * 1000)
                        dur = int(duration * 1000)
                        
                        self.events.append({
                            "name": task.task_id,
                            "cat": "task",
                            "ph": "X",
                            "ts": ts,
                            "dur": dur,
                            "pid": self.process_id,
                            "tid": thread_id,
                            "args": {
                                "task_id": task.task_id,
                                "task_name": task.name,
                                "priority": task.priority.name,
                                "runtime_type": task.runtime_type.value,
                                "resource_type": seg.resource_type.value,
                                "bandwidth": resource_unit.bandwidth,
                                "is_segmented": task.is_segmented
                            }
                        })
    
    def _add_binding_events(self):
        """æ·»åŠ èµ„æºç»‘å®šäº‹ä»¶"""
        if hasattr(self.scheduler, 'active_bindings'):
            for i, binding in enumerate(self.scheduler.active_bindings):
                # ä¸ºæ¯ä¸ªç»‘å®šçš„èµ„æºæ·»åŠ äº‹ä»¶
                for resource_id in binding.bound_resources:
                    thread_id = self.thread_ids.get(resource_id)
                    if thread_id:
                        ts = int(binding.binding_start * 1000)
                        dur = int((binding.binding_end - binding.binding_start) * 1000)
                        
                        self.events.append({
                            "name": f"Binding_{i}",
                            "cat": "resource_binding",
                            "ph": "X",
                            "ts": ts,
                            "dur": dur,
                            "pid": self.process_id,
                            "tid": thread_id,
                            "args": {
                                "binding_id": i,
                                "bound_resources": list(binding.bound_resources),
                                "resource_id": resource_id
                            }
                        })
    
    def _add_performance_markers(self):
        """æ·»åŠ æ€§èƒ½æ ‡è®°"""
        if not self.scheduler.schedule_history:
            return
        
        # è°ƒåº¦å¼€å§‹æ ‡è®°
        first_start = min(s.start_time for s in self.scheduler.schedule_history)
        self.events.append({
            "name": "Scheduling Start",
            "cat": "marker",
            "ph": "I",  # Instant event
            "ts": int(first_start * 1000),
            "pid": self.process_id,
            "tid": 1,
            "args": {"marker_type": "scheduling_start"}
        })
        
        # è°ƒåº¦ç»“æŸæ ‡è®°
        last_end = max(s.end_time for s in self.scheduler.schedule_history)
        self.events.append({
            "name": "Scheduling End",
            "cat": "marker",
            "ph": "I",
            "ts": int(last_end * 1000),
            "pid": self.process_id,
            "tid": 1,
            "args": {"marker_type": "scheduling_end"}
        })
        
        # æ·»åŠ ä»»åŠ¡ä¼˜å…ˆçº§æ ‡è®°
        priority_times = {}
        for schedule in self.scheduler.schedule_history:
            task = self.scheduler.tasks[schedule.task_id]
            priority = task.priority.name
            if priority not in priority_times:
                priority_times[priority] = []
            priority_times[priority].append(schedule.start_time)
        
        for priority, times in priority_times.items():
            for time_point in times:
                self.events.append({
                    "name": f"{priority} Task",
                    "cat": "priority",
                    "ph": "I",
                    "ts": int(time_point * 1000),
                    "pid": self.process_id,
                    "tid": 1,
                    "args": {"priority": priority}
                })
    
    def _write_trace_file(self, filename: str):
        """å†™å…¥è¿½è¸ªæ–‡ä»¶"""
        trace_data = {
            "traceEvents": self.events,
            "displayTimeUnit": "ms",
            "otherData": {
                "version": "NPU Scheduler Trace",
                "generator": "ChromeTracer",
                "timestamp": time.time(),
                "scheduler_info": {
                    "total_tasks": len(self.scheduler.schedule_history),
                    "total_resources": sum(len(resources) for resources in self.scheduler.resources.values()),
                    "npu_count": len(self.scheduler.resources[ResourceType.NPU]),
                    "dsp_count": len(self.scheduler.resources[ResourceType.DSP]),
                    "segmentation_enabled": getattr(self.scheduler, 'enable_segmentation', False)
                }
            }
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(trace_data, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… Chromeè¿½è¸ªæ–‡ä»¶å·²ä¿å­˜: {filename}")
            print(f"ğŸ“Š åŒ…å« {len(self.events)} ä¸ªè¿½è¸ªäº‹ä»¶")
            self._print_usage_instructions()
            
        except Exception as e:
            print(f"âŒ ä¿å­˜è¿½è¸ªæ–‡ä»¶å¤±è´¥: {e}")
    
    def _print_usage_instructions(self):
        """æ‰“å°ä½¿ç”¨è¯´æ˜"""
        print("\nğŸ” æŸ¥çœ‹Chromeè¿½è¸ªæ–‡ä»¶:")
        print("   1. æ‰“å¼€Chromeæµè§ˆå™¨")
        print("   2. åœ¨åœ°å€æ è¾“å…¥: chrome://tracing")
        print("   3. ç‚¹å‡» 'Load' æŒ‰é’®")
        print("   4. é€‰æ‹©ç”Ÿæˆçš„JSONæ–‡ä»¶")
        print("   5. ä½¿ç”¨ä»¥ä¸‹å¿«æ·é”®å¯¼èˆª:")
        print("      â€¢ W/S: æ”¾å¤§/ç¼©å°")
        print("      â€¢ A/D: å·¦ç§»/å³ç§»")
        print("      â€¢ é¼ æ ‡æ»šè½®: ç¼©æ”¾")
        print("      â€¢ é¼ æ ‡æ‹–æ‹½: å¹³ç§»")
    
    def export_performance_summary(self, filename: str = "performance_summary.json"):
        """å¯¼å‡ºæ€§èƒ½æ‘˜è¦"""
        if not self.scheduler.schedule_history:
            print("âš ï¸  æ²¡æœ‰è°ƒåº¦å†å²æ•°æ®")
            return
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        latencies = [s.end_time - s.start_time for s in self.scheduler.schedule_history]
        
        # èµ„æºåˆ©ç”¨ç‡
        resource_usage = {}
        total_time = max(s.end_time for s in self.scheduler.schedule_history)
        
        for schedule in self.scheduler.schedule_history:
            for res_type, res_id in schedule.assigned_resources.items():
                if res_id not in resource_usage:
                    resource_usage[res_id] = 0
                resource_usage[res_id] += schedule.end_time - schedule.start_time
        
        # è®¡ç®—åˆ©ç”¨ç‡ç™¾åˆ†æ¯”
        resource_utilization = {
            res_id: (usage / total_time) * 100 
            for res_id, usage in resource_usage.items()
        }
        
        # ä¼˜å…ˆçº§ç»Ÿè®¡
        priority_stats = {}
        for schedule in self.scheduler.schedule_history:
            task = self.scheduler.tasks[schedule.task_id]
            priority = task.priority.name
            if priority not in priority_stats:
                priority_stats[priority] = {"count": 0, "total_latency": 0}
            priority_stats[priority]["count"] += 1
            priority_stats[priority]["total_latency"] += schedule.end_time - schedule.start_time
        
        # è®¡ç®—å¹³å‡å»¶è¿Ÿ
        for priority, stats in priority_stats.items():
            stats["avg_latency"] = stats["total_latency"] / stats["count"]
        
        summary = {
            "timestamp": time.time(),
            "total_tasks": len(self.scheduler.schedule_history),
            "scheduling_window": total_time,
            "latency_stats": {
                "min": min(latencies),
                "max": max(latencies),
                "avg": sum(latencies) / len(latencies),
                "total": sum(latencies)
            },
            "resource_utilization": resource_utilization,
            "priority_statistics": priority_stats,
            "system_info": {
                "npu_count": len(self.scheduler.resources[ResourceType.NPU]),
                "dsp_count": len(self.scheduler.resources[ResourceType.DSP]),
                "segmentation_enabled": getattr(self.scheduler, 'enable_segmentation', False)
            }
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            print(f"ğŸ“ˆ æ€§èƒ½æ‘˜è¦å·²ä¿å­˜: {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ€§èƒ½æ‘˜è¦å¤±è´¥: {e}")
    
    def create_minimal_trace(self) -> List[Dict[str, Any]]:
        """åˆ›å»ºæœ€å°åŒ–çš„è¿½è¸ªæ•°æ®ï¼ˆç”¨äºå†…å­˜åˆ†æï¼‰"""
        minimal_events = []
        
        for schedule in self.scheduler.schedule_history:
            task = self.scheduler.tasks[schedule.task_id]
            
            # åªè®°å½•åŸºæœ¬çš„ä»»åŠ¡æ‰§è¡Œä¿¡æ¯
            for res_type, res_id in schedule.assigned_resources.items():
                minimal_events.append({
                    "name": task.task_id,
                    "start": schedule.start_time,
                    "end": schedule.end_time,
                    "resource": res_id,
                    "priority": task.priority.name,
                    "runtime": task.runtime_type.value
                })
        
        return minimal_events


def export_multiple_formats(scheduler, base_filename: str = "scheduler_trace"):
    """å¯¼å‡ºå¤šç§æ ¼å¼çš„è¿½è¸ªæ–‡ä»¶"""
    tracer = ChromeTracer(scheduler)
    
    # Chromeè¿½è¸ªæ ¼å¼
    tracer.export(f"{base_filename}.json")
    
    # æ€§èƒ½æ‘˜è¦
    tracer.export_performance_summary(f"{base_filename}_summary.json")
    
    # æœ€å°åŒ–è¿½è¸ªï¼ˆCSVæ ¼å¼ï¼‰
    minimal_trace = tracer.create_minimal_trace()
    try:
        import csv
        with open(f"{base_filename}_minimal.csv", 'w', newline='', encoding='utf-8') as f:
            if minimal_trace:
                writer = csv.DictWriter(f, fieldnames=minimal_trace[0].keys())
                writer.writeheader()
                writer.writerows(minimal_trace)
        print(f"ğŸ“„ æœ€å°åŒ–è¿½è¸ªå·²ä¿å­˜: {base_filename}_minimal.csv")
    except ImportError:
        print("âš ï¸  CSVæ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡æœ€å°åŒ–è¿½è¸ªå¯¼å‡º")


if __name__ == "__main__":
    # æµ‹è¯•è¿½è¸ªå™¨åŠŸèƒ½
    print("=== Chromeè¿½è¸ªå™¨æµ‹è¯• ===")
    print("è¯·é€šè¿‡ä¸»ç¨‹åºè¿è¡Œæ¥æµ‹è¯•è¿½è¸ªåŠŸèƒ½")